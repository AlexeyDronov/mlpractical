{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class GradientFlowPlotter:\n",
    "    def __init__(self, model, plot_func):\n",
    "        self.model = model\n",
    "        self.plot_func = plot_func  # Function to create the plot\n",
    "\n",
    "    def plot_grad_flow(self, named_parameters):\n",
    "        all_grads = []\n",
    "        layers = []\n",
    "\n",
    "        for name, parameter in named_parameters:\n",
    "            if parameter.grad is not None:  # Check if the gradient exists\n",
    "                layers.append(name)\n",
    "                grad_mean = parameter.grad.abs().mean().detach().cpu().numpy()\n",
    "                all_grads.append(grad_mean)\n",
    "            else:\n",
    "                layers.append(name)\n",
    "                all_grads.append(0.0)  # Use 0 if no gradient is available\n",
    "\n",
    "        return self.plot_func(all_grads, layers)\n",
    "\n",
    "    def plot_all_epochs(self, model_path_format, num_epochs, dummy_input):\n",
    "        for epoch in range(1, num_epochs + 1):\n",
    "            # Load the model state\n",
    "            model_path = model_path_format.format(epoch)\n",
    "            self.model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n",
    "            self.model.eval()\n",
    "\n",
    "            # Perform a forward and backward pass with dummy input\n",
    "            dummy_output = self.model(dummy_input)\n",
    "            loss = dummy_output.mean()  # Simplified dummy loss for demonstration\n",
    "            self.model.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            # Plot gradient flow for this epoch\n",
    "            print(f\"Plotting gradient flow for epoch {epoch}\")\n",
    "            plt = self.plot_grad_flow(self.model.named_parameters())\n",
    "            plt.show()  # Display the plot for the current epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_func_def(all_grads, layers):\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    Plot function definition to plot the average gradient with respect to the number of layers in the given model\n",
    "    :param all_grads: Gradients wrt weights for each layer in the model.\n",
    "    :param layers: Layer names corresponding to the model parameters\n",
    "    :return: plot for gradient flow\n",
    "    \"\"\"\n",
    "    plt.plot(all_grads, alpha=0.3, color=\"b\")\n",
    "    plt.hlines(0, 0, len(all_grads)+1, linewidth=1, color=\"k\" )\n",
    "    plt.xticks(range(0,len(all_grads), 1), layers, rotation=\"vertical\")\n",
    "    plt.xlim(xmin=0, xmax=len(all_grads))\n",
    "    plt.xlabel(\"Layers\")\n",
    "    plt.ylabel(\"Average Gradient\")\n",
    "    plt.title(\"Gradient flow\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return plt\n",
    "    \n",
    "\n",
    "def plot_grad_flow(named_parameters):\n",
    "    \"\"\"\n",
    "    The function is being called in Line 298 of this file. \n",
    "    Receives the parameters of the model being trained. Returns plot of gradient flow for the given model parameters.\n",
    "    \n",
    "    \"\"\"\n",
    "    all_grads = []\n",
    "    layers = []\n",
    "    \n",
    "    \"\"\"\n",
    "    Complete the code in the block below to collect absolute mean of the gradients for each layer in all_grads with the             layer names in layers.\n",
    "    \"\"\"\n",
    "    ########################################\n",
    "    #TODO write your code here\n",
    "    \n",
    "    ########################################\n",
    "    \n",
    "    for layer, parameter in named_parameters:\n",
    "        if \"bias\" in layer:\n",
    "            continue\n",
    "        layer_name = layer.replace('.weight', '').replace('.bias', '').replace(\"layer_dict.\", \"\").replace(\".\", \"_\")\n",
    "\n",
    "        mean_grad = parameter.grad.abs().mean().item()\n",
    "        layers.append(layer_name)\n",
    "        all_grads.append(mean_grad)\n",
    "    \n",
    "    plt = plot_func_def(all_grads, layers)\n",
    "    return plt\n",
    "# plot_grad_flow(model.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building basic block of ConvolutionalNetwork using input shape (100, 3, 32, 32)\n",
      "torch.Size([100, 32, 32, 32])\n",
      "torch.Size([100, 32, 32, 32])\n",
      "torch.Size([100, 32, 32, 32])\n",
      "torch.Size([100, 32, 32, 32])\n",
      "torch.Size([100, 32, 32, 32])\n",
      "torch.Size([100, 32, 32, 32])\n",
      "torch.Size([100, 32, 16, 16])\n",
      "torch.Size([100, 32, 16, 16])\n",
      "torch.Size([100, 32, 16, 16])\n",
      "torch.Size([100, 32, 16, 16])\n",
      "torch.Size([100, 32, 16, 16])\n",
      "torch.Size([100, 32, 16, 16])\n",
      "torch.Size([100, 32, 8, 8])\n",
      "torch.Size([100, 32, 8, 8])\n",
      "torch.Size([100, 32, 8, 8])\n",
      "torch.Size([100, 32, 8, 8])\n",
      "torch.Size([100, 32, 8, 8])\n",
      "torch.Size([100, 32, 8, 8])\n",
      "torch.Size([100, 32, 4, 4])\n",
      "shape before final linear layer torch.Size([100, 32, 1, 1])\n",
      "Block is built, output volume is torch.Size([100, 100])\n"
     ]
    }
   ],
   "source": [
    "from pytorch_mlp_framework.model_architectures import *\n",
    "# Assuming you have a PyTorch model defined as `MyModel`\n",
    "model = ConvolutionalNetwork(  # initialize our network object, in this case a ConvNet\n",
    "    input_shape=(100, 3, 32, 32),\n",
    "    num_output_classes=100, num_filters=32, use_bias=False,\n",
    "    num_blocks_per_stage=5, num_stages=3,\n",
    "    processing_block_type=ConvolutionalProcessingBlock,\n",
    "    dimensionality_reduction_block_type=ConvolutionalDimensionalityReductionBlock)\n",
    "\n",
    "\n",
    "dummy_input = torch.randn(100, 3, 32, 32)  # Adjust to your input shape\n",
    "dummy_target = torch.randint(0, 100, (100,))  # Dummy target for classification\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Path format for saved models\n",
    "PATH = \"/Users/AlexDronov/Desktop/MSc Data Science/mlpractical/\\\n",
    "VGG_38_experiment/saved_models/train_model_{}\"\n",
    "# for epoch in range(0, 100):\n",
    "#     checkpoint = torch.load(PATH.format(epoch), map_location=torch.device('cpu'), weights_only=False)\n",
    "#     state_dict = checkpoint['network']\n",
    "#     state_dict = {key.replace(\"model.\", \"\"): value for key, value in state_dict.items()}\n",
    "#     model.load_state_dict(state_dict)\n",
    "#     outputs = model(dummy_input)\n",
    "\n",
    "#     # Compute loss\n",
    "#     loss = criterion(outputs, dummy_target)\n",
    "\n",
    "#     # Backward pass to compute gradients\n",
    "#     model.zero_grad()  # Clear previous gradients\n",
    "#     loss.backward()\n",
    "\n",
    "#     # Plot gradient flow\n",
    "#     plot_grad_flow(model.named_parameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n",
      "39\n"
     ]
    }
   ],
   "source": [
    "layer_grads = {}\n",
    "layers = []\n",
    "for layer, parameter in model.named_parameters():\n",
    "        layer_name = layer.replace('.weight', '').replace('.bias', '')# .replace(\"layer_dict.\", \"\").replace(\".\", \"_\")\n",
    "\n",
    "        mean_grad = parameter.grad.abs().mean().item()\n",
    "        if layer_name not in layer_grads:\n",
    "            layer_grads[layer_name] = mean_grad\n",
    "        else:\n",
    "            layer_grads[layer_name] = (layer_grads[layer_name] + mean_grad)/2\n",
    "\n",
    "layers = list(layer_grads.keys())\n",
    "values = list(layer_grads.values())\n",
    "print(len(values))\n",
    "print(len(layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_conv_conv_0\n",
      "input_conv_bn_0\n",
      "input_conv_bn_0\n",
      "block_0_0_conv_0\n",
      "block_0_0_conv_1\n",
      "block_0_1_conv_0\n",
      "block_0_1_conv_1\n",
      "block_0_2_conv_0\n",
      "block_0_2_conv_1\n",
      "block_0_3_conv_0\n",
      "block_0_3_conv_1\n",
      "block_0_4_conv_0\n",
      "block_0_4_conv_1\n",
      "reduction_block_0_conv_0\n",
      "reduction_block_0_conv_0\n",
      "reduction_block_0_conv_1\n",
      "reduction_block_0_conv_1\n",
      "block_1_0_conv_0\n",
      "block_1_0_conv_1\n",
      "block_1_1_conv_0\n",
      "block_1_1_conv_1\n",
      "block_1_2_conv_0\n",
      "block_1_2_conv_1\n",
      "block_1_3_conv_0\n",
      "block_1_3_conv_1\n",
      "block_1_4_conv_0\n",
      "block_1_4_conv_1\n",
      "reduction_block_1_conv_0\n",
      "reduction_block_1_conv_0\n",
      "reduction_block_1_conv_1\n",
      "reduction_block_1_conv_1\n",
      "block_2_0_conv_0\n",
      "block_2_0_conv_1\n",
      "block_2_1_conv_0\n",
      "block_2_1_conv_1\n",
      "block_2_2_conv_0\n",
      "block_2_2_conv_1\n",
      "block_2_3_conv_0\n",
      "block_2_3_conv_1\n",
      "block_2_4_conv_0\n",
      "block_2_4_conv_1\n",
      "reduction_block_2_conv_0\n",
      "reduction_block_2_conv_0\n",
      "reduction_block_2_conv_1\n",
      "reduction_block_2_conv_1\n",
      "logit_linear_layer\n",
      "logit_linear_layer\n"
     ]
    }
   ],
   "source": [
    "for layer, parameter in model.named_parameters():\n",
    "    print(layer.replace('.weight', '').replace('.bias', '').replace(\"layer_dict.\", \"\").replace(\".\", \"_\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
